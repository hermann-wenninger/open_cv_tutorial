{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title IMPORTS\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "#@title IMAGE HELPERS\n",
    "def imshow(img,size=10):\n",
    "  img = img / 2 + 0.5     \n",
    "  npimg = img.numpy()\n",
    "  plt.figure(figsize=(size, size))\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()\n",
    "#@title LOADING DATA\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,),(0.5,))\n",
    "                ])\n",
    "to_image = transforms.ToPILImage()\n",
    "trainset = MNIST(root='./data/', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "device(type='cuda')\n",
    "#@title GENERATOR & DISCRIMINATOR\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, latent_dim=128, output_dim=784):\n",
    "    super(Generator, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.output_dim = output_dim\n",
    "    self.generator = nn.Sequential(\n",
    "        nn.Linear(self.latent_dim, 256),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(256, 512),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Linear(1024, self.output_dim),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.generator(x)\n",
    "    x = x.view(-1, 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, input_dim=784, output_dim=1):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.output_dim = output_dim\n",
    "    self.discriminator = nn.Sequential(\n",
    "      nn.Linear(self.input_dim, 1024),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Dropout(0.3),\n",
    "      nn.Linear(1024, 512),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Dropout(0.3),\n",
    "      nn.Linear(512, 256),\n",
    "      nn.LeakyReLU(0.2),\n",
    "      nn.Dropout(0.3),\n",
    "      nn.Linear(256, self.output_dim),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.discriminator(x)\n",
    "        return x\n",
    "#@title CREATE MODEKS, OPTIMIZERS AND LOSS FUNCTION (CRITERION)\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "def noise(n, n_features=128):\n",
    "    return Variable(torch.randn(n, n_features)).to(device)\n",
    "\n",
    "def make_ones(size):\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "def make_zeros(size):\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data.to(device)\n",
    "#@title TRAINING FUNCTIONS\n",
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    n = real_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction_real = discriminator(real_data)\n",
    "    loss_real = loss_fn(prediction_real, make_ones(n))\n",
    "    loss_real.backward()\n",
    "\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    loss_fake = loss_fn(prediction_fake, make_zeros(n))\n",
    "    \n",
    "    loss_fake.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss_real + loss_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    n = fake_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction = discriminator(fake_data)\n",
    "    loss = loss_fn(prediction, make_ones(n))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "#@title TRAINING\n",
    "epochs = 250\n",
    "k = 1\n",
    "test_noise = noise(64)\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "for epoch in range(epochs):\n",
    "    g_loss = 0.0\n",
    "    d_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        imgs, _ = data\n",
    "        n = len(imgs)\n",
    "        for j in range(k):\n",
    "            fake_data = generator(noise(n)).detach()\n",
    "            real_data = imgs.to(device)\n",
    "            d_loss += train_discriminator(d_optim, real_data, fake_data)\n",
    "        fake_data = generator(noise(n))\n",
    "        g_loss += train_generator(g_optim, fake_data)\n",
    "\n",
    "    img = generator(test_noise).cpu().detach()        \n",
    "    g_losses.append(g_loss/i)\n",
    "    d_losses.append(d_loss/i)\n",
    "    clear_output()\n",
    "    print(f'Epoch {epoch+1}: g_loss: {g_loss/i:.8f} d_loss: {d_loss/i:.8f}')\n",
    "    imshow(make_grid(img))   \n",
    "Epoch 16: g_loss: 2.15769434 d_loss: 0.74215227\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-8-a20ca86f7957> in <module>()\n",
    "      9     g_loss = 0.0\n",
    "     10     d_loss = 0.0\n",
    "---> 11     for i, data in enumerate(train_loader):\n",
    "     12         imgs, _ = data\n",
    "     13         n = len(imgs)\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py in __next__(self)\n",
    "    433         if self._sampler_iter is None:\n",
    "    434             self._reset()\n",
    "--> 435         data = self._next_data()\n",
    "    436         self._num_yielded += 1\n",
    "    437         if self._dataset_kind == _DatasetKind.Iterable and \\\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py in _next_data(self)\n",
    "    473     def _next_data(self):\n",
    "    474         index = self._next_index()  # may raise StopIteration\n",
    "--> 475         data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
    "    476         if self._pin_memory:\n",
    "    477             data = _utils.pin_memory.pin_memory(data)\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py in fetch(self, possibly_batched_index)\n",
    "     42     def fetch(self, possibly_batched_index):\n",
    "     43         if self.auto_collation:\n",
    "---> 44             data = [self.dataset[idx] for idx in possibly_batched_index]\n",
    "     45         else:\n",
    "     46             data = self.dataset[possibly_batched_index]\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py in <listcomp>(.0)\n",
    "     42     def fetch(self, possibly_batched_index):\n",
    "     43         if self.auto_collation:\n",
    "---> 44             data = [self.dataset[idx] for idx in possibly_batched_index]\n",
    "     45         else:\n",
    "     46             data = self.dataset[possibly_batched_index]\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py in __getitem__(self, index)\n",
    "    104 \n",
    "    105         if self.transform is not None:\n",
    "--> 106             img = self.transform(img)\n",
    "    107 \n",
    "    108         if self.target_transform is not None:\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py in __call__(self, img)\n",
    "     65     def __call__(self, img):\n",
    "     66         for t in self.transforms:\n",
    "---> 67             img = t(img)\n",
    "     68         return img\n",
    "     69 \n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py in __call__(self, pic)\n",
    "    102             Tensor: Converted image.\n",
    "    103         \"\"\"\n",
    "--> 104         return F.to_tensor(pic)\n",
    "    105 \n",
    "    106     def __repr__(self):\n",
    "\n",
    "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py in to_tensor(pic)\n",
    "    100     img = img.permute((2, 0, 1)).contiguous()\n",
    "    101     if isinstance(img, torch.ByteTensor):\n",
    "--> 102         return img.float().div(255)\n",
    "    103     else:\n",
    "    104         return img\n",
    "\n",
    "KeyboardInterrupt: \n",
    "#@title HISTORY\n",
    "plt.plot(g_losses, label='Generator_Losses')\n",
    "plt.plot(d_losses, label='Discriminator Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
